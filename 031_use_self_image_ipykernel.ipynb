{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8446a09f-16a6-4103-8fea-2bb575d64f25",
   "metadata": {},
   "source": [
    "## 031. DEMO 專用共用 library folder 之 image容器 kernel\n",
    "<span style=\"color:red\">Change to Default kernel:   Image_S_home_pytorch_2.1.0-cuda11.8-cudnn8-devel</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c0ade8-71ef-4f04-8205-962e78a47788",
   "metadata": {},
   "source": [
    "### TRY IT\n",
    "1. Lauch  a new notebook tab\n",
    "2. Change to kernel:  Image_S_home_pytorch_2.1.0-cuda11.8-cudnn8-devel\n",
    "3. In first cell add content below\n",
    "\n",
    "```\n",
    "import os\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "Add_Binarry_Path=HOME+'/.local/bin:/usr/ubuntu_bin'\n",
    "os.environ['PATH']=os.environ['PATH']+':'+Add_Binarry_Path\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f85861f-0081-4292-a324-1ca99e02f62f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 初始環境設定\n",
    "import os\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "Add_Binarry_Path=HOME+'/.local/bin:/usr/ubuntu_bin'\n",
    "os.environ['PATH']=os.environ['PATH']+':'+Add_Binarry_Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81b7114e-8703-439b-aba0-31ab34e28344",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chainlit                                 0.7.604      /home/g00cjz00/.local/lib/python3.10/site-packages pip\n"
     ]
    }
   ],
   "source": [
    "# 安裝chainlit\n",
    "!pip install chainlit IProgress ipywidgets -q\n",
    "!pip list -v |grep chainlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24552997-84b9-4411-9bcc-839cc75800d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/g00cjz00/.local/bin/chainlit\n"
     ]
    }
   ],
   "source": [
    "# 安裝位置\n",
    "!which chainlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e4c9070-53c2-4991-afa1-b813db391602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerate\t\t    httpx\t\t  opentelemetry-bootstrap\n",
      "accelerate-config\t    huggingface-cli\t  opentelemetry-instrument\n",
      "accelerate-estimate-memory  humanfriendly\t  optimum-cli\n",
      "accelerate-launch\t    ipython\t\t  pygmentize\n",
      "chainlit\t\t    ipython3\t\t  rouge\n",
      "coloredlogs\t\t    jupyter\t\t  transformers-cli\n",
      "datasets-cli\t\t    jupyter-kernel\t  undill\n",
      "dotenv\t\t\t    jupyter-kernelspec\t  uvicorn\n",
      "filetype\t\t    jupyter-migrate\t  watchfiles\n",
      "get_gprof\t\t    jupyter-run\n",
      "get_objgraph\t\t    jupyter-troubleshoot\n"
     ]
    }
   ],
   "source": [
    "# 真正路徑\n",
    "!ls $HOME/libraryFolder/S_home_pytorch_2.1.0-cuda11.8-cudnn8-devel/local/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a2916f1-2c71-450e-b488-c70f873fbc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "!pip3 install huggingface-hub hf_transfer -q\n",
    "!pip3 install transformers optimum -q\n",
    "!pip3 install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/  -q # Use cu117 if on CUDA 11.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "416c3b93-bdf9-4270-810c-c29efbae0808",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to successfully use the Power of Three and the Power of Four in many kinds of scenarios. For example, there are situations where we may be dealing with the following things:\\n\\nThe situation in which we'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model https://huggingface.co/gpt2\n",
    "from transformers import pipeline\n",
    "generator = pipeline(task=\"text-generation\")\n",
    "generator(\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c25929e-cbd7-4ead-96fc-3b37b686e939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Image_S_home_pytorch_2.1.0-cuda11.8-cudnn8-devel",
   "language": "python",
   "name": "s_home_pytorch_2.1.0-cuda11.8-cudnn8-devel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
