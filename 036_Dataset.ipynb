{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfd25270-f6b6-427e-a602-4db45809284c",
   "metadata": {},
   "source": [
    "## Reference \n",
    "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o\n",
    "https://huggingface.co/datasets/huangyt/FINETUNE3\n",
    "https://huggingface.co/erhwenkuo\n",
    "https://huggingface.co/datasets/erhwenkuo/school_math_0.25m-zhtw\n",
    "https://huggingface.co/datasets/erhwenkuo/medical_dialogue-chinese-zhtw\n",
    "https://huggingface.co/datasets/DataAgent/medical-qa-instruction-zhtw\n",
    "```\n",
    "Model Card for Model ID\n",
    "在llama-2-13b上使用huangyt/FINETUNE3資料集進行訓練，總資料筆數約3.3w\n",
    "\n",
    "Fine-Tuning Information\n",
    "GPU: RTX4090 (single core / 24564MiB)\n",
    "model: meta-llama/Llama-2-13b-hf\n",
    "dataset: huangyt/FINETUNE3 (共約3.3w筆訓練集)\n",
    "peft_type: LoRA\n",
    "lora_rank: 16\n",
    "lora_target: q_proj, k_proj, v_proj, o_proj\n",
    "per_device_train_batch_size: 8\n",
    "gradient_accumulation_steps: 8\n",
    "learning_rate : 4e-4\n",
    "epoch: 1\n",
    "precision: bf16\n",
    "quantization: load_in_4bit\n",
    "\n",
    "Fine-Tuning Detail\n",
    "train_loss: 0.579\n",
    "train_runtime: 4:6:11 (use deepspeed)\n",
    "Evaluation\n",
    "與Llama-2-13b比較4種Benchmark，包含ARC、HellaSwag、MMLU、TruthfulQA\n",
    "評估結果使用本地所測的分數，並使用load_in_8bit\n",
    "```\n",
    "```\n",
    "python finetune.py \\\n",
    "    --load_4bit \\\n",
    "    --base_model 'meta-llama/Llama-2-13b-hf' \\\n",
    "    --data_path 'yahma/alpaca-cleaned' \\\n",
    "    --output_dir './lora-alpaca' \\\n",
    "    --batch_size 8 \\\n",
    "    --micro_batch_size 4 \\\n",
    "    --num_epochs 1 \\\n",
    "    --learning_rate 4e-4 \\\n",
    "    --cutoff_len 512 \\\n",
    "    --val_set_size 2000 \\\n",
    "    --lora_r 8 \\\n",
    "    --lora_alpha 16 \\\n",
    "    --lora_dropout 0.05 \\\n",
    "    --lora_target_modules '[q_proj, k_proj, v_proj, o_proj]' \\\n",
    "    --train_on_inputs \\\n",
    "    --group_by_length\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d110ed55-4754-4682-a513-f5dc1b19a8d0",
   "metadata": {},
   "source": [
    "## A. KERNEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45749416-10f2-41e3-a346-aa182d11c31c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 036. DEMO Dataset 使用專用 library folder 之 image容器 kernel\n",
    "<span style=\"color:red\">Change to Default kernel:   Image_S_home_alpaca-lora_latest</span>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af92298b-2952-4e3a-b96d-812995b4db68",
   "metadata": {},
   "source": [
    "### TRY IT\n",
    "1. Lauch  a new notebook tab\n",
    "2. Change to kernel:  Image_S_home_pytorch_2.1.0-cuda11.8-cudnn8-devel\n",
    "3. In first cell add content below\n",
    "\n",
    "```\n",
    "import os\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "Add_Binarry_Path=HOME+'/.local/bin:/usr/ubuntu_bin'\n",
    "os.environ['PATH']=os.environ['PATH']+':'+Add_Binarry_Path\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf4e586-5cf6-4a2c-9e2f-3b699cece832",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "Add_Binarry_Path=HOME+'/.local/bin:/usr/ubuntu_bin'\n",
    "os.environ['PATH']=os.environ['PATH']+':'+Add_Binarry_Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e59f5a-8c21-4baf-9947-a221276accf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install datasets -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8c9f7f-10d3-48fc-86d9-a39cd9eafd58",
   "metadata": {},
   "source": [
    "## 1. Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9beae9-429c-462c-969c-83aee3276724",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 讀取數據集，take可以取得該數據集前n筆資料\n",
    "dataset = load_dataset(\"DataAgent/medical-qa-instruction-zhtw\", split=\"train\", streaming=True)\n",
    "\n",
    "# 提取所需欄位並建立新的字典列表\n",
    "limit=30000\n",
    "extracted_data = []\n",
    "for example in dataset:\n",
    "    extracted_example = {\n",
    "        \"instruction\": example[\"instruction\"],\n",
    "        \"input\": example[\"input\"],\n",
    "        \"output\": example[\"output\"]\n",
    "    }\n",
    "    extracted_data.append(extracted_example)\n",
    "    if len(extracted_data) == limit:\n",
    "        break\n",
    "\n",
    "# 指定 JSON 文件名稱\n",
    "json_filename = \"medical-qa-instruction-zhtw.json\"\n",
    "\n",
    "# 寫入 JSON 文件\n",
    "with open(json_filename, \"w\") as json_file:\n",
    "    json.dump(extracted_data, json_file, indent=4)\n",
    "\n",
    "print(f\"數據已提取並保存為 {json_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6035d-a970-42ee-a1c0-c65df4688e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd. read_json ( 'medical-qa-instruction-zhtw.json' )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da286db-f10f-4809-8427-acb636b8fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf alpaca-lora\n",
    "!cp -rf /work/u00cjz00/slurm_jobs/demo/alpaca-lora ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90206438-ae60-4b5d-b533-681bcf78f978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp finetune.py alpaca-lora/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9597e0-4c3a-450c-bc67-93cd4493470b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd alpaca-lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7575777f-5a11-48c5-9663-43336ccceded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt -q\n",
    "!pip install protobuf install accelerate==0.24.1 bitsandbytes transformers accelerate bitsandbytes bitsandbytes==0.41 scipy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5c5eb3-3608-4cfc-8dbc-5cb4ac08649c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 finetune.py \\\n",
    "    --base_model '/work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf' \\\n",
    "    --data_path '../medical-qa-instruction-zhtw.json' \\\n",
    "    --output_dir './lora-alpaca' \\\n",
    "    --batch_size 128 \\\n",
    "    --micro_batch_size 4 \\\n",
    "    --num_epochs 3 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --cutoff_len 512 \\\n",
    "    --val_set_size 2000 \\\n",
    "    --lora_r 8 \\\n",
    "    --lora_alpha 16 \\\n",
    "    --lora_dropout 0.05 \\\n",
    "    --lora_target_modules '[q_proj,v_proj]' \\\n",
    "    --train_on_inputs \\\n",
    "    --group_by_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af944f6-5311-4fce-bde3-0ca9eebc0002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
