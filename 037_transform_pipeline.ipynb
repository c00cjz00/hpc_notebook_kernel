{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb4f0422-b608-443b-bd3e-96a9602f79f6",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd25270-f6b6-427e-a602-4db45809284c",
   "metadata": {},
   "source": [
    "## Reference \n",
    "- https://huggingface.co/docs/transformers/v4.18.0/en/pipeline_tutorial\n",
    "- https://transformers.run/intro/2021-12-08-transformers-note-1/\n",
    "- https://github.com/huggingface/transformers/issues/26959\n",
    "- https://github.com/huggingface/transformers/issues/26959"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d110ed55-4754-4682-a513-f5dc1b19a8d0",
   "metadata": {},
   "source": [
    "## A. KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a715c1-2f7f-4654-8d39-84cf24238a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kernel Image_pytorch_2.1.0-cuda11.8-cudnn8-devel\n",
    "# ipykernel 3.10\n",
    "#!/opt/ohpc/Taiwania3/libs/singularity/3.10.2/bin/singularity exec --nv -B /work /work/u00cjz00/nvidia/pytorch_2.0.1-cuda11.7-cudnn8-runtime.sif pip install -q ipykernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392b312b-1acf-4b8e-8296-fe958345a02f",
   "metadata": {},
   "source": [
    "## B. SET PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e3fda8c-8c32-49c2-924b-714156017f78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 新增可讀取套件安裝位置\n",
    "import os\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "Add_Binarry_Path=HOME+'/.local/bin'\n",
    "os.environ['PATH']=Add_Binarry_Path+':'+os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec1be47-c2f3-432d-8531-befe4cb14dfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 安裝套件 GPTQ\n",
    "!pip install xformers optimum bitsandbytes sentence_transformers einops arxiv openai chromadb tiktoken pymupdf langchain chainlit transformers IProgress ipywidgets accelerate -q\n",
    "!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/  -q # Use cu117 if on CUDA 11.7\n",
    "#!pip3 install transformers>=4.32.0 optimum>=1.12.0 -q\n",
    "#!pip3 install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/ -q # Use cu117 if on CUDA 11.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "460a2b0d-87c7-4076-a2be-6ae912a6e127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from auto_gptq import AutoGPTQForCausalLM\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c98542-9cb6-4a90-9648-3397e4446eb0",
   "metadata": {},
   "source": [
    "## 推理管道 Pipelines for inference\n",
    "pipeline ()可以使用模型中心的任何模型來推理各種任務，例如文字生成、圖像分割和音訊分類。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c9c579-025c-41e9-8e12-cdaa3fce38a5",
   "metadata": {},
   "source": [
    "### 1. 情緒分析\n",
    "pipeline 模型會自動完成以下三個步驟：\n",
    "- 將文字預處理為模型可以理解的格式；\n",
    "- 將預處理好的文字送入模型；\n",
    "- 對模型的預測值進行後處理，輸出人類可以理解的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b33112d-0d25-4ec8-a833-683e00c8d788",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c8e605fcaf435f8759d5e5876d16eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c76eaccaa7b49f7b43975dc22c12743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0564acb8494b40c98aec68a98052ab77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598046541213989},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###  model https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\n",
    "from transformers import pipeline\n",
    "generator = pipeline(\"sentiment-analysis\")\n",
    "generator(\"I've been waiting for a HuggingFace course my whole life.\")\n",
    "generator([\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40149e29-2386-4af2-aea3-82bfdccfa6e4",
   "metadata": {},
   "source": [
    "### 2. 零訓練樣本分類\n",
    "零訓練樣本分類pipeline 允許我們在不提供任何標註資料的情況下自訂分類標籤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "822d60b3-acde-4c17-836c-160cbc04f4ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144a248fdb324992be549cc404134df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d30d5a9165648879dea3473f6194ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a31872396b4f7cb751baa4b77dc2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9ef72be8634669a0d282e99263a5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb3adbe822049a69ff86df2637a358c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffaeead8b06d44f7ad9c38cd3ca273b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8445951342582703, 0.1119769886136055, 0.04342784732580185]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model https://huggingface.co/facebook/bart-large-mnli\n",
    "from transformers import pipeline\n",
    "generator = pipeline(\"zero-shot-classification\")\n",
    "generator(\"This is a course about the Transformers library\",candidate_labels=[\"education\", \"politics\", \"business\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee635f-471f-4e67-92a0-41ee06dbdd2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. 文字生成 text-generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76872b49-9c37-4b35-a176-31aaf84313b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d87d83c0be4d15922a60619dab9dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa32474ab36a4578b42ec358f0c549cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to connect digital and physical objects together to make your work life more fluid and memorable. A simple task set up using the touch of a button, this course will quickly demonstrate how to get started using touch to'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model https://huggingface.co/gpt2\n",
    "from transformers import pipeline\n",
    "generator = pipeline(task=\"text-generation\")\n",
    "generator(\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae818f18-2c50-40fc-9853-8ac367c78908",
   "metadata": {},
   "source": [
    "## 這些pipeline 背後做了什麼？\n",
    "- 預處理(preprocessing)，將原始文字轉換為模型可以接受的輸入格式；\n",
    "- 將處理好的輸入送入模型；\n",
    "- 對模型的輸出進行後處理(postprocessing)，將其轉換為人類方便閱讀的格式。\n",
    "\n",
    "![NN] <img src=\"https://transformers.run/assets/img/transformers-note-1/full_nlp_pipeline.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd07d2-a6ca-4de5-9747-3d52d96162dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model Llama-2-7b-chat-hf\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "MODEL_ID = \"/work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_ID, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "generator = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "generator(\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe1a731f-7935-4bd0-a910-1dd6ef7b630e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f311e56abc864d7f8df62c0bc55fa197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to create a successful YouTube channel, from finding your niche and creating content to building a community and monetizing your channel.ἱ\\n\\n\\n\\n'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model Llama-2-7b-chat-hf load_in_4bit\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "MODEL_ID = \"/work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "# load model in 4-bit\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_ID, quantization_config=quantization_config, device_map=\"auto\")\n",
    "generator = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer,max_length=200)\n",
    "generator(\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "450aa392-40d3-487a-8fcb-5296f1c2eced",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping module injection for FusedLlamaMLPForQuantizedModel as currently not supported with use_triton=False.\n",
      "The model 'LlamaGPTQForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to create a successful and sustainable business by leveraging the power of social media marketing.\\nIn this course, you will learn how to:\\n1. Identify your target audience and create buyer personas\\n2. Develop a social media marketing strategy that aligns with your business goals\\n3. Create engaging and shareable content that drives traffic and conversions\\n4. Use paid social media advertising to reach a wider audience\\n5. Measure and track your social media performance using analytics tools\\n6. Optimize your social media campaigns for maximum ROI\\n7. Utilize influencer marketing to reach new audiences\\n8. Leverage user-generated content to build brand loyalty\\n9. Use social media to improve customer service and build brand reputation\\n10. Stay up-to-date with the latest social media trends and best practices\\nBy the end of this'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model Llama-2-7b-chat-hf GPTQ\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from auto_gptq import AutoGPTQForCausalLM\n",
    "MODEL_ID = \"/work/u00cjz00/slurm_jobs/github/models/Llama-2-7B-Chat-GPTQ\"\n",
    "model = AutoGPTQForCausalLM.from_quantized(MODEL_ID,  device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True, use_safetensors=True, use_triton=False)\n",
    "generator = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "generator(\"In this course, we will teach you how to\",max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73d164d5-c058-4370-b5e8-0494130312b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping module injection for FusedLlamaMLPForQuantizedModel as currently not supported with use_triton=False.\n",
      "The model 'LlamaGPTQForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
      "<</SYS>>\n",
      "Tell me about AI[/INST]\n",
      "\n",
      "Hello! I'm here to assist you with any questions or topics you have in mind. AI (Artificial Intelligence) is a fascinating field that has been rapidly advancing in recent years. AI refers to the ability of machines to perform tasks that typically require human intelligence, such as learning, problem-solving, decision-making, and perception.\n",
      "There are several types of AI, including:\n",
      "1. Narrow or weak AI: This type of AI is designed to perform a specific task, such as playing chess or recognizing faces.\n",
      "2. General or strong AI: This type of AI is designed to perform any intellectual task that a human can, such as reasoning, problem-solving, and learning.\n",
      "3. Superintelligent AI: This type of AI is significantly more intelligent than the best human minds, and could potentially solve complex problems that are currently unsolvable.\n",
      "4. Artificial general intelligence (AGI): This type of AI is designed to perform any intellectual task that a human can, and is considered the holy grail of AI research.\n",
      "Some of the most promising applications of AI include:\n",
      "1. Natural Language Processing (NLP): This technology allows computers to understand, interpret, and generate human language, making it easier for humans to communicate with machines.\n",
      "2. Machine Learning (ML): This technology enables computers to learn from data without being explicitly programmed, allowing them to improve their performance over time.\n",
      "3. Robotics: This technology involves the design and development of robots that can perform tasks that typically require human intelligence, such as assembly, maintenance, and transportation.\n",
      "However, there are also concerns and challenges associated with AI, such as:\n",
      "1. Bias: AI systems can perpetuate biases and discrimination if they are trained on biased data or designed without considering ethical considerations.\n",
      "2. Privacy: AI systems often rely on collecting and processing large amounts of personal data, which raises concerns about privacy and data protection.\n",
      "3. Job displacement: There is a risk that AI could displace human workers, particularly in industries where tasks are repetitive or can be easily automated.\n",
      "It is important to note that AI is a rapidly evolving field, and its impact on society will depend on how it is developed and used. As A\n"
     ]
    }
   ],
   "source": [
    "# model Llama-2-7b-chat-hf GPTQ + configure +  prompt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from auto_gptq import AutoGPTQForCausalLM\n",
    "MODEL_ID = \"/work/u00cjz00/slurm_jobs/github/models/Llama-2-7B-Chat-GPTQ\"\n",
    "model = AutoGPTQForCausalLM.from_quantized(MODEL_ID,  device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "\n",
    "# Inference can also be done using transformers' pipeline\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    top_k=40,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "prompt = \"Tell me about AI\"\n",
    "prompt_template=f'''[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "{prompt}[/INST]\n",
    "\n",
    "'''\n",
    "print(generator(prompt_template)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7a43272-612b-49f2-90ce-00ef7e2d0626",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping module injection for FusedLlamaMLPForQuantizedModel as currently not supported with use_triton=False.\n",
      "The model 'LlamaGPTQForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" create a successful online business and make money online through various legitimate means, including:\\n\\n1. Affiliate marketing\\n2. Online tutoring and coaching\\n3. Selling digital products and courses\\n4. Creating and selling an online service-based business\\n5. Building a blog or website and monetizing it through advertising, sponsorships, and affiliate marketing\\nWe will cover everything you need to know to get started, from finding your niche and building a website, to marketing and promoting your business and reaching your target audience. By the end of this course, you will have a solid understanding of how to build a successful online business and make money online, and you will be well on your way to achieving your financial goals.\\nSo, if you're ready to take your business to the next level and start making money online, enroll in this course today and let's get started!\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model Llama-2-7b-chat-hf GPTQ + configure +  prompt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from auto_gptq import AutoGPTQForCausalLM\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain import PromptTemplate\n",
    "MODEL_ID = \"/work/u00cjz00/slurm_jobs/github/models/Llama-2-7B-Chat-GPTQ\"\n",
    "model = AutoGPTQForCausalLM.from_quantized(MODEL_ID,  device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "\n",
    "# Inference can also be done using transformers' pipeline\n",
    "#generator = pipeline(\"text-generation\",model=model,tokenizer=tokenizer,\n",
    "#    max_new_tokens=512,\n",
    "#    do_sample=True,\n",
    "#    top_p=0.95,\n",
    "#    top_k=40,\n",
    "#    repetition_penalty=1.1\n",
    "#)\n",
    "\n",
    "generator=pipeline(\"text-generation\", model=model, tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    max_length=1000,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "\n",
    "llm=HuggingFacePipeline(pipeline=generator, model_kwargs={'temperature':0.7})\n",
    "llm(\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bd3348b-e5e2-4183-a8fd-a2e6e8043a5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We define our prompt template in the following way:\n",
    "prompt_template = \"\"\"<s>[INST] <<SYS>>\n",
    "{{ You are a helpful AI Assistant}}<<SYS>>\n",
    "###\n",
    "\n",
    "Previous Conversation:\n",
    "'''\n",
    "{history}\n",
    "'''\n",
    "\n",
    "{{{input}}}[/INST]\n",
    "\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=['input', 'history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b536902d-256e-4c52-9e92-db10d5045641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 為了防止上下文緩衝區變得非常大，我們可以使用ConversationBufferWindowMemory. 只需修改定義鏈的程式碼部分即可。然後，再次運行鏈條！\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferWindowMemory(k=5)\n",
    "llm_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee56d1a0-6982-4ce3-aee5-f87bfc0bde05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Of course! Elephants are fascinating creatures that are known for their intelligence, social behavior, and unique characteristics. Here are some interesting facts about elephants:\\n\\n1. Largest Living Thing: Elephants are the largest living things on Earth, with African elephants weighing up to 6 tons (12,000 pounds) and Asian elephants weighing up to 5 tons (10,000 pounds).\\n2. Intelligent Creatures: Elephants are highly intelligent animals that have been observed using tools, solving problems, and even displaying empathy and self-awareness.\\n3. Social Behavior: Elephants live in complex societies with strict hierarchies and social bonds. They communicate with each other through a variety of sounds, including trumpets, rumbles, and squeaks.\\n4. Long Lifespan: Elephants can live for up to 70 years in the wild and over 80 years in captivity, making them one of the longest-living land animals.\\n5. Unique Trunk: Elephants have a highly specialized trunk that is used for breathing, drinking, and grasping objects. The trunk is made up of muscles and cartilage and can be used in a variety of ways, including touching, grasping, and manipulating objects.\\n6. Great Memories: Elephants have excellent memories and can remember specific events and individuals from years ago. They are also known to show empathy and grieve when a loved one dies.\\n7. Important Role in Ecosystems: Elephants play a crucial role in maintaining ecosystem balance in their native habitats. They help disperse seeds, create pathways for other animals, and maintain forest structures.\\n8. Endangered Status: Unfortunately, many elephant populations are endangered due to habitat loss, poaching, and human-wildlife conflict. Conservation efforts are necessary to protect these magnificent creatures and their habitats.\\n\\nDo you have any questions or would you like to learn more about elephants?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run(\"Tell me about elephant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91a0f76f-7f0c-47d1-a87a-547a3dd1c9f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a helpful AI assistant, I'm happy to provide information on various topics. However, I must inform you that the previous conversation you provided contains 8 points of interesting facts about elephants, and none of them relate to the weight of elephants. Therefore, I cannot provide an answer to your question regarding how much an elephant weighs.\\nElephants are indeed massive creatures, with African elephants typically weighing between 5,000 to 14,000 pounds (2,268 to 6,350 kilograms), while Asian elephants typically weigh between 3,000 to 6,000 pounds (1,361 to 2,722 kilograms). If you have any further questions or would like to know more about elephants, please feel free to ask!\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run(\"How weight is it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eba9ed21-365a-423e-b732-f6d42e4f89fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a helpful AI assistant, I'm glad you're interested in learning more about elephants! There are several places where you can observe these incredible creatures in person or virtually. Here are some options:\\n1. National Zoos and Wildlife Sanctuaries: Many national zoos and wildlife sanctuaries around the world have elephants in their care. These institutions often offer educational programs, exhibits, and conservation initiatives dedicated to protecting elephants and their habitats. Some notable examples include the San Diego Zoo, the Bronx Zoo, and the Elephant Nature Park in Thailand.\\n2. Wildlife Conservation Organizations: Several organizations are dedicated to protecting and conserving elephant populations in the wild. For example, the World Wildlife Fund (WWF) and the International Union for Conservation of Nature (IUCN) work to safeguard habitats, monitor elephant populations, and combat poaching. You can visit their websites to learn more about their efforts and how you can support them.\\n3. Safari Tours: Going on a safari tour is an excellent way to experience elephants in their natural habitats. Professional guides and tour operators can help you locate elephants, understand their behavior, and appreciate their beauty. Popular elephant-watching destinations include Africa (for both African and Asian elephants), India, and Southeast Asia.\\n4. Documentaries and Videos: You can watch documentaries or videos about elephants on streaming platforms such as Netflix, YouTube, or BBC iPlayer. These media provide an insightful look into elephant behavior, migration patterns, and conservation challenges.\\n5. Virtual Tours: With advancements in technology, you can now take virtual tours of elephant habitats and sanctuaries from the comfort of your home. Many organizations offer immersive experiences that allow you to explore elephant environments without leaving your living room.\\nThese are just a few examples of places where you can see and learn about elephants. Remember to always support conservation efforts and responsible wildlife tourism practices to ensure these magnificent creatures continue to thrive. Would you like more information on elephants or conservation efforts?\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run(\" Where can I see it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a38814e9-d461-4f85-8cb2-0b5820c59e23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Tell me about elephant\\nAI: Of course! Elephants are fascinating creatures that are known for their intelligence, social behavior, and unique characteristics. Here are some interesting facts about elephants:\\n\\n1. Largest Living Thing: Elephants are the largest living things on Earth, with African elephants weighing up to 6 tons (12,000 pounds) and Asian elephants weighing up to 5 tons (10,000 pounds).\\n2. Intelligent Creatures: Elephants are highly intelligent animals that have been observed using tools, solving problems, and even displaying empathy and self-awareness.\\n3. Social Behavior: Elephants live in complex societies with strict hierarchies and social bonds. They communicate with each other through a variety of sounds, including trumpets, rumbles, and squeaks.\\n4. Long Lifespan: Elephants can live for up to 70 years in the wild and over 80 years in captivity, making them one of the longest-living land animals.\\n5. Unique Trunk: Elephants have a highly specialized trunk that is used for breathing, drinking, and grasping objects. The trunk is made up of muscles and cartilage and can be used in a variety of ways, including touching, grasping, and manipulating objects.\\n6. Great Memories: Elephants have excellent memories and can remember specific events and individuals from years ago. They are also known to show empathy and grieve when a loved one dies.\\n7. Important Role in Ecosystems: Elephants play a crucial role in maintaining ecosystem balance in their native habitats. They help disperse seeds, create pathways for other animals, and maintain forest structures.\\n8. Endangered Status: Unfortunately, many elephant populations are endangered due to habitat loss, poaching, and human-wildlife conflict. Conservation efforts are necessary to protect these magnificent creatures and their habitats.\\n\\nDo you have any questions or would you like to learn more about elephants?\\nHuman: How weight is it?\\nAI: As a helpful AI assistant, I'm happy to provide information on various topics. However, I must inform you that the previous conversation you provided contains 8 points of interesting facts about elephants, and none of them relate to the weight of elephants. Therefore, I cannot provide an answer to your question regarding how much an elephant weighs.\\nElephants are indeed massive creatures, with African elephants typically weighing between 5,000 to 14,000 pounds (2,268 to 6,350 kilograms), while Asian elephants typically weigh between 3,000 to 6,000 pounds (1,361 to 2,722 kilograms). If you have any further questions or would like to know more about elephants, please feel free to ask!\\nHuman:  Where can I see it?\\nAI: As a helpful AI assistant, I'm glad you're interested in learning more about elephants! There are several places where you can observe these incredible creatures in person or virtually. Here are some options:\\n1. National Zoos and Wildlife Sanctuaries: Many national zoos and wildlife sanctuaries around the world have elephants in their care. These institutions often offer educational programs, exhibits, and conservation initiatives dedicated to protecting elephants and their habitats. Some notable examples include the San Diego Zoo, the Bronx Zoo, and the Elephant Nature Park in Thailand.\\n2. Wildlife Conservation Organizations: Several organizations are dedicated to protecting and conserving elephant populations in the wild. For example, the World Wildlife Fund (WWF) and the International Union for Conservation of Nature (IUCN) work to safeguard habitats, monitor elephant populations, and combat poaching. You can visit their websites to learn more about their efforts and how you can support them.\\n3. Safari Tours: Going on a safari tour is an excellent way to experience elephants in their natural habitats. Professional guides and tour operators can help you locate elephants, understand their behavior, and appreciate their beauty. Popular elephant-watching destinations include Africa (for both African and Asian elephants), India, and Southeast Asia.\\n4. Documentaries and Videos: You can watch documentaries or videos about elephants on streaming platforms such as Netflix, YouTube, or BBC iPlayer. These media provide an insightful look into elephant behavior, migration patterns, and conservation challenges.\\n5. Virtual Tours: With advancements in technology, you can now take virtual tours of elephant habitats and sanctuaries from the comfort of your home. Many organizations offer immersive experiences that allow you to explore elephant environments without leaving your living room.\\nThese are just a few examples of places where you can see and learn about elephants. Remember to always support conservation efforts and responsible wildlife tourism practices to ensure these magnificent creatures continue to thrive. Would you like more information on elephants or conservation efforts?\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b08f040-ff34-450d-b17b-5a23fee8e94c",
   "metadata": {},
   "source": [
    "### 4. 自動問答\n",
    "自動問答pipeline 可以根據給定的上下文回答問題，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "876725b4-beac-48e1-9995-65c665e6c18b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9241172075271606, 'start': 28, 'end': 34, 'answer': 'Taiwan'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model https://huggingface.co/distilbert-base-cased-distilled-squad)\n",
    "from transformers import pipeline\n",
    "generator = pipeline(\"question-answering\")\n",
    "generator(question=\"Where am I form?\",context=\"My name is Sylvain and I in Taiwan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df223b96-4c9d-4957-bb7f-f707116a8e05",
   "metadata": {},
   "source": [
    "### 5. 自動摘要\n",
    "自動摘要pipeline 旨在將長文本壓縮成短文本，並且還要盡可能保留原文的主要訊息，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc661b68-891a-4561-9be2-c7efa31e5d86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil, electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India, as well as other industrial countries in Europe and Asia, continue to encourage and advance engineering .'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model https://huggingface.co/sshleifer/distilbart-cnn-12-6\n",
    "from transformers import pipeline\n",
    "generator = pipeline(\"summarization\")\n",
    "generator(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acbbe53-bd41-4eba-905e-7ee9ef515d84",
   "metadata": {},
   "source": [
    "## 這些pipeline 背後做了什麼？\n",
    "- 預處理(preprocessing)，將原始文字轉換為模型可以接受的輸入格式；\n",
    "- 將處理好的輸入送入模型；\n",
    "- 對模型的輸出進行後處理(postprocessing)，將其轉換為人類方便閱讀的格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d221650-d466-47b7-b93f-2bd5e03e39dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "![alt text](https://transformers.run/assets/img/transformers-note-1/full_nlp_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fae3aa-fa2b-42f1-a560-0cbd8010306c",
   "metadata": {},
   "source": [
    "### 6. vision_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8abca4a7-06a8-4ba7-bccc-36c6f7e305bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 5dca96d (https://huggingface.co/google/vit-base-patch16-224).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4403040111064911, 'label': 'lynx, catamount'},\n",
       " {'score': 0.03433402255177498,\n",
       "  'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'},\n",
       " {'score': 0.03214792534708977,\n",
       "  'label': 'snow leopard, ounce, Panthera uncia'},\n",
       " {'score': 0.023539021611213684, 'label': 'Egyptian cat'},\n",
       " {'score': 0.02303403615951538, 'label': 'tiger cat'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model google/vit-base-patch16-224\n",
    "from transformers import pipeline\n",
    "vision_classifier = pipeline(task=\"image-classification\")\n",
    "vision_classifier(\n",
    "    images=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f41a2a-f378-4b14-afdf-2fd7288b8adf",
   "metadata": {},
   "source": [
    "### 7. audio_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4985cf-d863-4a3d-a18a-d078b6d02c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "audio_classifier = pipeline(\n",
    "    task=\"audio-classification\", model=\"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\n",
    ")\n",
    "audio_classifier(\"jfk_moon_speech.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c601f4-cddb-4f92-92b2-662b354a3ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Image_S_home_pytorch_2.1.0-cuda11.8-cudnn8-devel",
   "language": "python",
   "name": "s_home_pytorch_2.1.0-cuda11.8-cudnn8-devel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
